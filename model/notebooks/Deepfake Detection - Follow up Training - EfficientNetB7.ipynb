{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cd4616c",
   "metadata": {},
   "source": [
    "# Deepfake Detection - Model Training EfficientNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93939235",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63a35a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.9.12'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa3bf975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fc2f822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.9.1', '2.9.0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.__version__, keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8b46fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check GPUs available\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Enables use of the GPU on a Mac using plaidml (ignore otherwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "696f75ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97af7d92",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7973839f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"../dataset-sample-faces.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7558e14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_filename</th>\n",
       "      <th>image_fullpath</th>\n",
       "      <th>face_confidence</th>\n",
       "      <th>label</th>\n",
       "      <th>video_filename</th>\n",
       "      <th>video_fullpath</th>\n",
       "      <th>video_dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id0_0000_1.png</td>\n",
       "      <td>../extracted_faces/id0_0000/id0_0000_1.png</td>\n",
       "      <td>0.997610</td>\n",
       "      <td>REAL</td>\n",
       "      <td>id0_0000.mp4</td>\n",
       "      <td>../datasets/Celeb-DF-v2/Celeb-real/id0_0000.mp4</td>\n",
       "      <td>Celeb-DF-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id0_0000_15.png</td>\n",
       "      <td>../extracted_faces/id0_0000/id0_0000_15.png</td>\n",
       "      <td>0.996413</td>\n",
       "      <td>REAL</td>\n",
       "      <td>id0_0000.mp4</td>\n",
       "      <td>../datasets/Celeb-DF-v2/Celeb-real/id0_0000.mp4</td>\n",
       "      <td>Celeb-DF-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id0_0000_29.png</td>\n",
       "      <td>../extracted_faces/id0_0000/id0_0000_29.png</td>\n",
       "      <td>0.999750</td>\n",
       "      <td>REAL</td>\n",
       "      <td>id0_0000.mp4</td>\n",
       "      <td>../datasets/Celeb-DF-v2/Celeb-real/id0_0000.mp4</td>\n",
       "      <td>Celeb-DF-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id0_0000_43.png</td>\n",
       "      <td>../extracted_faces/id0_0000/id0_0000_43.png</td>\n",
       "      <td>0.995511</td>\n",
       "      <td>REAL</td>\n",
       "      <td>id0_0000.mp4</td>\n",
       "      <td>../datasets/Celeb-DF-v2/Celeb-real/id0_0000.mp4</td>\n",
       "      <td>Celeb-DF-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id0_0000_57.png</td>\n",
       "      <td>../extracted_faces/id0_0000/id0_0000_57.png</td>\n",
       "      <td>0.997212</td>\n",
       "      <td>REAL</td>\n",
       "      <td>id0_0000.mp4</td>\n",
       "      <td>../datasets/Celeb-DF-v2/Celeb-real/id0_0000.mp4</td>\n",
       "      <td>Celeb-DF-v2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_filename                               image_fullpath  \\\n",
       "0   id0_0000_1.png   ../extracted_faces/id0_0000/id0_0000_1.png   \n",
       "1  id0_0000_15.png  ../extracted_faces/id0_0000/id0_0000_15.png   \n",
       "2  id0_0000_29.png  ../extracted_faces/id0_0000/id0_0000_29.png   \n",
       "3  id0_0000_43.png  ../extracted_faces/id0_0000/id0_0000_43.png   \n",
       "4  id0_0000_57.png  ../extracted_faces/id0_0000/id0_0000_57.png   \n",
       "\n",
       "   face_confidence label video_filename  \\\n",
       "0         0.997610  REAL   id0_0000.mp4   \n",
       "1         0.996413  REAL   id0_0000.mp4   \n",
       "2         0.999750  REAL   id0_0000.mp4   \n",
       "3         0.995511  REAL   id0_0000.mp4   \n",
       "4         0.997212  REAL   id0_0000.mp4   \n",
       "\n",
       "                                    video_fullpath video_dataset  \n",
       "0  ../datasets/Celeb-DF-v2/Celeb-real/id0_0000.mp4   Celeb-DF-v2  \n",
       "1  ../datasets/Celeb-DF-v2/Celeb-real/id0_0000.mp4   Celeb-DF-v2  \n",
       "2  ../datasets/Celeb-DF-v2/Celeb-real/id0_0000.mp4   Celeb-DF-v2  \n",
       "3  ../datasets/Celeb-DF-v2/Celeb-real/id0_0000.mp4   Celeb-DF-v2  \n",
       "4  ../datasets/Celeb-DF-v2/Celeb-real/id0_0000.mp4   Celeb-DF-v2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(DATASET_PATH)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea5cd744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image_filename',\n",
       " 'image_fullpath',\n",
       " 'face_confidence',\n",
       " 'label',\n",
       " 'video_filename',\n",
       " 'video_fullpath',\n",
       " 'video_dataset']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e85f7e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REAL    48200\n",
       "FAKE    46832\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29db191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(n=40000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5def2f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REAL    20184\n",
       "FAKE    19816\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cf6e75",
   "metadata": {},
   "source": [
    "Although, there is a slight imbalance in the dataset as seen above, we sampled the number of \"FAKE\" videos equal to the number of \"REAL\" videos in the notebook [Deepfake Detection - Dataset Preparation.ipynb](./Deepfake%20Detection%20-%20Dataset%20Preparation.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b524eddc",
   "metadata": {},
   "source": [
    "## Data Splitting\n",
    "\n",
    "To ensure that images from a video in the train dataset is not in the validation/test dataset, a custom split function was made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3c1a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(data, test_size, column, shuffle=False, random_state=1):\n",
    "  \"\"\"Splits the dataframe based on unique values in a given \n",
    "  column.\"\"\"\n",
    "  # Gets a list of unique videos \n",
    "  videos = list(data[column].unique())\n",
    "  n = len(videos)\n",
    "  k = int(0.2 * n)\n",
    "\n",
    "  if shuffle:\n",
    "    data = data.sample(frac=1)\n",
    "\n",
    "  # Sets the random state\n",
    "  random.seed(random_state)\n",
    "  split_videos = random.sample(videos, k)\n",
    "\n",
    "  df1 = data[data[column].isin(split_videos)]\n",
    "  df2 = data[~data[column].isin(split_videos)]\n",
    "  \n",
    "  assert(len(df1[df1.isin(df2)].dropna()) == 0)\n",
    "  \n",
    "  df1.sort_index(inplace=True)\n",
    "  df2.sort_index(inplace=True)\n",
    "  \n",
    "  return df2, df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd721fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michelle\\AppData\\Local\\Temp\\ipykernel_21648\\1251354954.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.sort_index(inplace=True)\n",
      "C:\\Users\\Michelle\\AppData\\Local\\Temp\\ipykernel_21648\\1251354954.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2.sort_index(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SPLIT = 0.2\n",
    "VAL_SPLIT = 0.25\n",
    "\n",
    "train_df, test_df = split_dataframe(data=data, \n",
    "                                    test_size=TRAIN_SPLIT,\n",
    "                                    column=\"video_filename\",\n",
    "                                    shuffle=True,\n",
    "                                    random_state=42)\n",
    "\n",
    "train_df, val_df = split_dataframe(data=data, \n",
    "                                  test_size=VAL_SPLIT,\n",
    "                                  column=\"video_filename\",\n",
    "                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a12d3423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FAKE    16125\n",
       "REAL    15885\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67c8b4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REAL    4299\n",
       "FAKE    3691\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66b16e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REAL    4299\n",
       "FAKE    3691\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba6de22",
   "metadata": {},
   "source": [
    "## Data Augmentation \n",
    "\n",
    "**Gaussian Noise:**\n",
    "\n",
    "**Random Erasing:** https://arxiv.org/abs/1708.04896\n",
    "    - Source code: https://github.com/zhunzhong07/Random-Erasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26f51b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def gaussian_noise(image, probability):\n",
    "  if random.uniform(0,1) > probability:\n",
    "    return image\n",
    "  row,col,ch= image.shape\n",
    "  mean = 0\n",
    "  var = 0.01 # slightly reduced\n",
    "  sigma = var ** 0.5\n",
    "  gauss = np.random.normal(mean,sigma,(row,col))\n",
    "  noisy = image\n",
    "  for i in range(ch):\n",
    "    noisy[:,:,i] = image[:,:,i] + gauss\n",
    "  return noisy\n",
    "\n",
    "\n",
    "def random_erasing(img, probability):\n",
    "  \"\"\"\n",
    "  Performs Random Erasing in Random Erasing Data Augmentation by Zhong et al.\n",
    "\n",
    "  probability: The probability that the operation will be performed.\n",
    "  sl: min erasing area\n",
    "  sh: max erasing area\n",
    "  r1: min aspect ratio\n",
    "  mean: erasing value\n",
    "\n",
    "  Note: Code modified for img.shape parameters instead of img.size()\n",
    "  \"\"\"\n",
    "  # Source: https://github.com/zhunzhong07/Random-Erasing\n",
    "  if random.uniform(0,1) > probability:\n",
    "    return img\n",
    "\n",
    "  # Default params\n",
    "  mean = [0.4914, 0.4822, 0.4465]\n",
    "  sl = 0.02\n",
    "  sh = 0.4\n",
    "  r1 = 0.3\n",
    "\n",
    "  for attempt in range(100):\n",
    "    area = img.shape[0] * img.shape[1]\n",
    "\n",
    "    target_area = random.uniform(sl, sh) * area\n",
    "    aspect_ratio = random.uniform(r1, 1/r1)\n",
    "\n",
    "    h = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "    w = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "\n",
    "    if w < img.shape[0] and h < img.shape[1]:\n",
    "        x1 = random.randint(0, img.shape[1] - h)\n",
    "        y1 = random.randint(0, img.shape[0] - w)\n",
    "        if img.shape[2] == 3:\n",
    "            img[x1:x1+h, y1:y1+w, 0] = mean[0]\n",
    "            img[x1:x1+h, y1:y1+w, 1] = mean[1]\n",
    "            img[x1:x1+h, y1:y1+w, 2] = mean[2]\n",
    "        else:\n",
    "            img[0, x1:x1+h, y1:y1+w] = mean[0]\n",
    "\n",
    "        return img\n",
    "  return img\n",
    "\n",
    "class CustomDataGenerator(ImageDataGenerator):\n",
    "  '''\n",
    "  Custom image data generator.\n",
    "  Allows image compression and random erasing.\n",
    "  '''\n",
    "  def __init__(self, \n",
    "               gaussian_noise : float = 0., \n",
    "               random_erasing : float = 0.,\n",
    "               **kwargs):\n",
    "    super().__init__(preprocessing_function=self.custom_augmentations,\n",
    "                    **kwargs)\n",
    "    self.gaussian_noise = gaussian_noise\n",
    "    self.random_erasing = random_erasing\n",
    "  \n",
    "  def custom_augmentations(self, image):\n",
    "    image = gaussian_noise(image, self.gaussian_noise)\n",
    "    image = random_erasing(image, self.random_erasing)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "631b2157",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = CustomDataGenerator(rescale=1./255,\n",
    "                                  zoom_range=0.2,\n",
    "                                  rotation_range=0.1,\n",
    "                                  horizontal_flip=True,\n",
    "                                  # Custom augmentation probabilities\n",
    "                                  gaussian_noise=0.1,\n",
    "                                  random_erasing=0.3)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4d7ad64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32010 validated image filenames belonging to 2 classes.\n",
      "Found 7990 validated image filenames belonging to 2 classes.\n",
      "Found 7990 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_DIM = 256\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "  dataframe = train_df,\n",
    "  directory = \".\",\n",
    "  x_col = \"image_fullpath\",\n",
    "  y_col = \"label\",\n",
    "  batch_size = BATCH_SIZE,\n",
    "  seed = 42,\n",
    "  class_mode = \"binary\",\n",
    "  target_size=(IMAGE_DIM, IMAGE_DIM)\n",
    ")\n",
    "\n",
    "valid_generator = train_datagen.flow_from_dataframe(\n",
    "  dataframe = val_df,\n",
    "  directory = \".\",\n",
    "  x_col = \"image_fullpath\",\n",
    "  y_col = \"label\",\n",
    "  batch_size = BATCH_SIZE,\n",
    "  seed = 42,\n",
    "  class_mode = \"binary\",\n",
    "  target_size=(IMAGE_DIM, IMAGE_DIM)\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "  dataframe = test_df, \n",
    "  directory = \".\",\n",
    "  x_col = \"image_fullpath\",\n",
    "  y_col = \"label\",\n",
    "  batch_size=BATCH_SIZE,\n",
    "  seed = 42,\n",
    "  shuffle=False,\n",
    "  class_mode=\"binary\",\n",
    "  target_size=(IMAGE_DIM, IMAGE_DIM)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebb5bab",
   "metadata": {},
   "source": [
    "## EfficientNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "817778c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet:\n",
    "    def __init__(self, input_size, n_freeze=143, dropout=0.5):\n",
    "        self.input_size = input_size\n",
    "        self.n_freeze = n_freeze\n",
    "        self.dropout = dropout\n",
    "        self.model = self._initialise_model()\n",
    "        self.history = None\n",
    "    \n",
    "    def _initialise_model(self):\n",
    "        input_t = keras.Input(shape=self.input_size)\n",
    "        base_model = keras.applications.EfficientNetB7(\n",
    "            include_top=False,\n",
    "            weights=\"imagenet\",\n",
    "            input_tensor=input_t,\n",
    "        )\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(base_model)\n",
    "        model.add(keras.layers.GlobalAveragePooling2D()) # v1\n",
    "#         model.add(keras.layers.Flatten()) # v0\n",
    "        model.add(keras.layers.Dropout(self.dropout))\n",
    "        model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "        return model\n",
    "    \n",
    "    def train_model(self, train_generator, valid_generator,\n",
    "                   epochs, learning_rate=0.0001,\n",
    "                   save_model:str=None,\n",
    "                   verbose=1):\n",
    "        train_steps = len(train_generator)\n",
    "        val_steps = len(valid_generator)\n",
    "        check_point = keras.callbacks.ModelCheckpoint(\n",
    "            filepath=\"../weights/efficientnetb7-v7-{epoch:02d}.hdf5\",\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True\n",
    "        )\n",
    "        self.model.compile(\n",
    "            loss='binary_crossentropy',\n",
    "            optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        self.history = self.model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=train_steps,\n",
    "            epochs=epochs,\n",
    "            validation_data=valid_generator,\n",
    "            validation_steps=val_steps,\n",
    "            verbose=verbose,\n",
    "            callbacks=[check_point]\n",
    "        )\n",
    "        \n",
    "        if save_model is not None:\n",
    "          self.save_model(save_model)\n",
    "        return self.history.history\n",
    "\n",
    "    def save_model(self,filepath):\n",
    "        self.model.save(filepath)\n",
    "\n",
    "    def get_history(self):\n",
    "        return self.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "981a02bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v0 training - flatten layer\n",
    "model0 = EfficientNet(input_size=(IMAGE_DIM, IMAGE_DIM,3), n_freeze=-8, dropout=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831fc279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "history0 = model0.train_model(train_generator=train_generator,\n",
    "                            valid_generator=valid_generator,\n",
    "                            epochs=20,\n",
    "                            learning_rate=0.0001,\n",
    "                            save_model=\"../weights/efficientnetb7-v2.h5\")\n",
    "\n",
    "pickle_path = \"pickle/efficientnetb7-v2.pickle\"\n",
    "\n",
    "with open(pickle_path, \"wb\") as f:\n",
    "  pickle.dump(history0, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0992b01d",
   "metadata": {},
   "source": [
    "## Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6660588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = \"pickle/efficientnetb7-v2.pickle\"\n",
    "\n",
    "with open(pickle_path, \"rb\") as f:\n",
    "  history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e60c59a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_loss_and_accuracy(history, figsize=(15,6)):\n",
    "  fig, ax = plt.subplots(1, 2, figsize=figsize)\n",
    "  ax[0].plot(history['loss'], label='train_loss')\n",
    "  ax[0].plot(history['val_loss'], label='valid_loss')\n",
    "  ax[0].set_title(\"Loss\")\n",
    "  ax[0].set_xlabel(\"epoch\")\n",
    "  ax[0].set_ylabel(\"loss\")\n",
    "  ax[0].legend()\n",
    "  ax[1].plot(history['accuracy'], label='train_acc')\n",
    "  ax[1].plot(history['val_accuracy'], label='valid_acc')\n",
    "  ax[1].set_title(\"Accuracy\")\n",
    "  ax[1].set_xlabel(\"epoch\")\n",
    "  ax[1].set_ylabel(\"accuracy\")\n",
    "  ax[1].legend()\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "    \n",
    "# plot_loss_and_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669d9af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5871fe50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d833c536",
   "metadata": {},
   "source": [
    "## Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa4c6d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(model, test_generator):\n",
    "    # Runs prediction on test dataset\n",
    "    test_generator.reset()\n",
    "    pred = model.predict(test_generator,steps=len(test_generator), verbose=1)\n",
    "    \n",
    "    # Creates a dictionary to search for the video_filename: array of frame predictions\n",
    "    real_labels = test_generator.labels\n",
    "    filenames = test_generator.filenames\n",
    "    prediction = {}\n",
    "    real_prediction = {}\n",
    "    for f, p, r in zip(filenames, pred, real_labels):\n",
    "        pred_video_filename = test_df[test_df['image_fullpath'] == f]['video_filename'].iloc[0]\n",
    "        if pred_video_filename in prediction.keys():\n",
    "            prediction[pred_video_filename].append(p[0])\n",
    "            real_prediction[pred_video_filename].append(r)\n",
    "        else:\n",
    "            prediction[pred_video_filename] = [ p[0] ]\n",
    "            real_prediction[pred_video_filename] = [r]\n",
    "\n",
    "    # Averages the prediction scores for each video\n",
    "    prediction = { k: sum(v)/len(v) for k,v in prediction.items() }\n",
    "    real_prediction = { k: int(sum(v)/len(v)) for k,v in real_prediction.items() }\n",
    "    \n",
    "    pred_vid_filenames = list(prediction.keys())\n",
    "    pred_vid = list(prediction.values())\n",
    "    real_indices = list(real_prediction.values())\n",
    "    \n",
    "    return pred_vid_filenames, pred_vid, real_indices\n",
    "\n",
    "def predict_indices(pred, thresh=0.5):\n",
    "    return [1 if p > thresh else 0 for p in pred ]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def show_classification_report(test_y, pred_y):\n",
    "    report = classification_report(test_y, pred_y, digits=4, zero_division=0)\n",
    "    print(report)\n",
    "    \n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def show_confusion_matrix(test_y, pred_y, axis_labels):\n",
    "    confusion = confusion_matrix(test_y, pred_y)\n",
    "    confusion_normalized = confusion.astype(\"float\") / confusion.sum(axis=1)\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    ax = sns.heatmap(confusion_normalized, \n",
    "                     xticklabels=axis_labels, \n",
    "                     yticklabels=axis_labels,\n",
    "                     cmap='Blues', \n",
    "                     annot=True,\n",
    "                     fmt = '.2f',\n",
    "                     square = True\n",
    "    )\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbd77d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1998/1998 [==============================] - 1366s 682ms/step - loss: 0.2194 - accuracy: 0.9262\n",
      "1998/1998 [==============================] - 1418s 708ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.21942657232284546, 0.9261577129364014)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v0 - Flatten\n",
    "effnet = keras.models.load_model(\"../weights/efficientnetb7-v7-02.hdf5\")\n",
    "\n",
    "test_generator.reset()\n",
    "image_loss, image_acc = effnet.evaluate(test_generator)\n",
    "test_x, pred_y, test_y = model_predict(effnet, test_generator)\n",
    "\n",
    "image_loss, image_acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12a5f100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loss     : 0.21942657232284546\n",
      "Image accuracy : 0.9261577129364014\n"
     ]
    }
   ],
   "source": [
    "print(\"Image loss     :\", image_loss)\n",
    "print(\"Image accuracy :\", image_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4eaf7819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9537    0.9606    0.9571       279\n",
      "           1     0.9655    0.9595    0.9625       321\n",
      "\n",
      "    accuracy                         0.9600       600\n",
      "   macro avg     0.9596    0.9600    0.9598       600\n",
      "weighted avg     0.9600    0.9600    0.9600       600\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Converts predictions to binary\n",
    "pred_y_indices = predict_indices(pred_y, thresh=0.5)\n",
    "\n",
    "show_classification_report(test_y, pred_y_indices)\n",
    "\n",
    "axis_labels = list(test_generator.class_indices)\n",
    "show_confusion_matrix(test_y, pred_y_indices, axis_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313c70c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
