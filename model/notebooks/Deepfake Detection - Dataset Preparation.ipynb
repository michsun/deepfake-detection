{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b323e92e",
   "metadata": {},
   "source": [
    "# Deepfake Detection - Dataset Preparation\n",
    "\n",
    "In this notebook, we will be preparing the dataset for deepfake detection training and testing. The dataset will be a combination of the following datasets:\n",
    "1. **[Kaggle - Deepfake Detection Challenge](https://www.kaggle.com/c/deepfake-detection-challenge/data)**\n",
    "2. **[Celeb-DF](https://github.com/yuezunli/celeb-deepfakeforensics)**\n",
    "3. **[FaceForensics DeepfakeDetectionDataset](https://ai.googleblog.com/2019/09/contributing-data-to-deepfake-detection.html)**\n",
    "\n",
    "The process will be as follows:\n",
    "1. **Exploratory Data Analysis on datasets:** Create a dataframe for each dataset and conduct a simple EDA on each of the three datasets. \n",
    "2. **Collate datasets from source datasets:** The datasets currently each have their own structure/labelling format. We will be constructing single source dataset containing all videos used used for the training process.\n",
    "3. **Sampling dataset:** To ensure both classes are balanced.\n",
    "4. **Extracting faces from the sampled dataset:** Faces are extracted and formed into its own dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2249d59a",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5581234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.13'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07d9b891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "\n",
    "from IPython.display import Video\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3934f76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../datasets/Kaggle-dfdc',\n",
       " '../datasets/Celeb-DF-v2',\n",
       " '../datasets/DeepfakeDetectionDataset')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Folder names/locations\n",
    "BASE = \"../datasets\"\n",
    "\n",
    "KAGGLE_DFDC = \"Kaggle-dfdc\"\n",
    "CELEB_DF = \"Celeb-DF-v2\"\n",
    "FF_DFDC = \"DeepfakeDetectionDataset\"\n",
    "\n",
    "# Create full paths\n",
    "DATA_KAGGLE = os.path.join(BASE, KAGGLE_DFDC)\n",
    "DATA_CELEBDF = os.path.join(BASE, CELEB_DF)\n",
    "DATA_FACEFORENSICS = os.path.join(BASE, FF_DFDC)\n",
    "\n",
    "DATA_KAGGLE, DATA_CELEBDF, DATA_FACEFORENSICS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c170ec",
   "metadata": {},
   "source": [
    "## Dataset EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1558b174",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a969fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def isdir(fullpath: str) -> bool:\n",
    "    \"\"\"Returns true if is a file, and false if otherwise (a directory).\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(fullpath):\n",
    "            if os.path.isdir(fullpath):\n",
    "                return True\n",
    "            return False\n",
    "    except FileNotFoundError:\n",
    "        print(f'{fullpath} does not exist.')\n",
    "\n",
    "def iterate_files(directory: str) -> List:\n",
    "    \"\"\"Iterates over the files in the given directory and returns a list of \n",
    "    found files.\"\"\"\n",
    "    files = []\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        fullpath = os.path.join(directory, filename)\n",
    "        if (isdir(fullpath)):\n",
    "            files += iterate_files(fullpath)\n",
    "        else:\n",
    "            files.append(fullpath)\n",
    "    return files\n",
    "  \n",
    "def get_filename(source: str):\n",
    "    \"\"\"Returns the filename given a full path.\"\"\"\n",
    "    return os.path.basename(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f7460d",
   "metadata": {},
   "source": [
    "### Kaggle Deepfake Detection Dataset\n",
    "\n",
    "The original Microsoft Deepfake Detection dataset available on Kaggle comprises of .mp4 files containing videos of deepfake videos denoted by the string \"REAL\" or \"FAKE\" in the label file. The original dataset is over 470 GB, which is incredibly large and outside the limits of our training. Instead, we will **only be using the train sample videos** available in the Kaggle data explorer section.\n",
    "\n",
    "The dataset has been kept with the following folder structure:\n",
    "<!--TODO: Folder structure-->\n",
    "\n",
    "We will be starting off by exploring the labels contained in the `metadata.json` file that is contained in the `train_sample_videos` folder. The file has the following columns:\n",
    "- `filename` - the filename of the video\n",
    "- `label` - whether the video is REAL or FAKE\n",
    "- `original` - in the case that a train set video is FAKE, the original video is listed here\n",
    "- `split` - this is always equal to \"train\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4adf224",
   "metadata": {},
   "source": [
    "#### Create dataframe from labels file: `metadata.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfc3a871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3433"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Folders for the Kaggle dataset\n",
    "data1_paths = [\n",
    "  \"dfdc_train_part_0\",\n",
    "  \"dfdc_train_part_1\",\n",
    "  \"train_sample_videos\",\n",
    "]\n",
    "label_file = \"metadata.json\"\n",
    "\n",
    "# \n",
    "label_dicts = []\n",
    "for path in data1_paths:\n",
    "  data1_label_path = os.path.join(DATA_KAGGLE, path, label_file)\n",
    "  with open(data1_label_path,'r', encoding='utf-8') as f:\n",
    "     file = json.load(f)\n",
    "  # Add indicator of which folder the data comes from\n",
    "  for k in file.keys():\n",
    "    file[k]['path'] = path\n",
    "  label_dicts.append(file)\n",
    "\n",
    "data1_dict = {}\n",
    "# Merge/concatenate dictionaries\n",
    "for dictionary in label_dicts:\n",
    "  data1_dict = dict(**data1_dict, **dictionary)\n",
    "\n",
    "len(data1_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d343f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('owxbbpjpch.mp4', {'label': 'FAKE', 'split': 'train', 'original': 'wynotylpnm.mp4', 'path': 'dfdc_train_part_0'})\n"
     ]
    }
   ],
   "source": [
    "# Preview the first line of the dictionary \n",
    "print(next(iter(data1_dict.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cb9666b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>fullpath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aagfhgtpmv.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>../datasets/Kaggle-dfdc/train_sample_videos/aa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aapnvogymq.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>../datasets/Kaggle-dfdc/train_sample_videos/aa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaqaifqrwn.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>../datasets/Kaggle-dfdc/dfdc_train_part_0/aaqa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aassnaulhq.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>../datasets/Kaggle-dfdc/dfdc_train_part_1/aass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aayrffkzxn.mp4</td>\n",
       "      <td>REAL</td>\n",
       "      <td>../datasets/Kaggle-dfdc/dfdc_train_part_0/aayr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abarnvbtwb.mp4</td>\n",
       "      <td>REAL</td>\n",
       "      <td>../datasets/Kaggle-dfdc/train_sample_videos/ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abebnhqyzv.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>../datasets/Kaggle-dfdc/dfdc_train_part_1/abeb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abhggqdift.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>../datasets/Kaggle-dfdc/dfdc_train_part_0/abhg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>abofeumbvv.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>../datasets/Kaggle-dfdc/train_sample_videos/ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abqwwspghj.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>../datasets/Kaggle-dfdc/train_sample_videos/ab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename label                                           fullpath\n",
       "0  aagfhgtpmv.mp4  FAKE  ../datasets/Kaggle-dfdc/train_sample_videos/aa...\n",
       "1  aapnvogymq.mp4  FAKE  ../datasets/Kaggle-dfdc/train_sample_videos/aa...\n",
       "2  aaqaifqrwn.mp4  FAKE  ../datasets/Kaggle-dfdc/dfdc_train_part_0/aaqa...\n",
       "3  aassnaulhq.mp4  FAKE  ../datasets/Kaggle-dfdc/dfdc_train_part_1/aass...\n",
       "4  aayrffkzxn.mp4  REAL  ../datasets/Kaggle-dfdc/dfdc_train_part_0/aayr...\n",
       "5  abarnvbtwb.mp4  REAL  ../datasets/Kaggle-dfdc/train_sample_videos/ab...\n",
       "6  abebnhqyzv.mp4  FAKE  ../datasets/Kaggle-dfdc/dfdc_train_part_1/abeb...\n",
       "7  abhggqdift.mp4  FAKE  ../datasets/Kaggle-dfdc/dfdc_train_part_0/abhg...\n",
       "8  abofeumbvv.mp4  FAKE  ../datasets/Kaggle-dfdc/train_sample_videos/ab...\n",
       "9  abqwwspghj.mp4  FAKE  ../datasets/Kaggle-dfdc/train_sample_videos/ab..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restructure dictionary for pandas dataframe input\n",
    "filenames = list(data1_dict.keys())\n",
    "labels = [ data1_dict[name]['label'] for name in filenames ]\n",
    "fullpaths = [ os.path.join(DATA_KAGGLE, data1_dict[name]['path'], name) for name in filenames]\n",
    "labels_dict = {\n",
    "  'filename': filenames,\n",
    "  'label': labels,\n",
    "  'fullpath': fullpaths\n",
    "}\n",
    "\n",
    "# Create dataframe1\n",
    "data1 = pd.DataFrame(labels_dict)\n",
    "data1 = data1.sort_values(by='filename', ignore_index=True)\n",
    "data1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3683e848",
   "metadata": {},
   "source": [
    "#### Simple EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54002545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3433, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7196351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique inputs: 3433\n"
     ]
    }
   ],
   "source": [
    "# Validate unique values\n",
    "print(\"Unique inputs:\", len(data1['filename'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c19bbb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FAKE    3162\n",
       "REAL     271\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42541e28",
   "metadata": {},
   "source": [
    "### Celeb-DF-v2\n",
    "\n",
    "Celeb-DF-v2 is a datasets generated dfor deepfake forensics containing 590 original videos collected from YouTube with subjects of different ages, ethnic groups and genders, and 5639 corresponding DeepFake videos. \n",
    "\n",
    "The dataset has been kept with the following folder structure:\n",
    "```\n",
    "Celeb-DF-v2\n",
    "|--- Celeb-real # 590 Celebrity videos downloaded from YouTube\n",
    "|--- YouTube-real # 300 Additional videos downloaded from YouTube\n",
    "|--- Celeb-synthesis # 5639 Synthesized videos from Celeb-real\n",
    "|--- List_of_testing_videos.txt # 518 videos\n",
    "```\n",
    "\n",
    "Thus, the dataset has a total of 6529, with 890 \"REAL\" videos and 5639 \"FAKE\" videos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172da43a",
   "metadata": {},
   "source": [
    "#### Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2653f1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(890, 5639)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subfolder names\n",
    "yt_real = \"YouTube-real\"\n",
    "celeb_real = \"Celeb-real\"\n",
    "celeb_fake = \"Celeb-synthesis\"\n",
    "\n",
    "real_data_path = iterate_files(os.path.join(DATA_CELEBDF, yt_real)) + iterate_files(os.path.join(DATA_CELEBDF, celeb_real))\n",
    "fake_data_path = iterate_files(os.path.join(DATA_CELEBDF, celeb_fake))\n",
    "\n",
    "len(real_data_path), len(fake_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df867ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>fullpath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000.mp4</td>\n",
       "      <td>REAL</td>\n",
       "      <td>../datasets/Celeb-DF-v2/YouTube-real/00000.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001.mp4</td>\n",
       "      <td>REAL</td>\n",
       "      <td>../datasets/Celeb-DF-v2/YouTube-real/00001.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00002.mp4</td>\n",
       "      <td>REAL</td>\n",
       "      <td>../datasets/Celeb-DF-v2/YouTube-real/00002.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00003.mp4</td>\n",
       "      <td>REAL</td>\n",
       "      <td>../datasets/Celeb-DF-v2/YouTube-real/00003.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00004.mp4</td>\n",
       "      <td>REAL</td>\n",
       "      <td>../datasets/Celeb-DF-v2/YouTube-real/00004.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00005.mp4</td>\n",
       "      <td>REAL</td>\n",
       "      <td>../datasets/Celeb-DF-v2/YouTube-real/00005.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00006.mp4</td>\n",
       "      <td>REAL</td>\n",
       "      <td>../datasets/Celeb-DF-v2/YouTube-real/00006.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00007.mp4</td>\n",
       "      <td>REAL</td>\n",
       "      <td>../datasets/Celeb-DF-v2/YouTube-real/00007.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00008.mp4</td>\n",
       "      <td>REAL</td>\n",
       "      <td>../datasets/Celeb-DF-v2/YouTube-real/00008.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00009.mp4</td>\n",
       "      <td>REAL</td>\n",
       "      <td>../datasets/Celeb-DF-v2/YouTube-real/00009.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename label                                        fullpath\n",
       "0  00000.mp4  REAL  ../datasets/Celeb-DF-v2/YouTube-real/00000.mp4\n",
       "1  00001.mp4  REAL  ../datasets/Celeb-DF-v2/YouTube-real/00001.mp4\n",
       "2  00002.mp4  REAL  ../datasets/Celeb-DF-v2/YouTube-real/00002.mp4\n",
       "3  00003.mp4  REAL  ../datasets/Celeb-DF-v2/YouTube-real/00003.mp4\n",
       "4  00004.mp4  REAL  ../datasets/Celeb-DF-v2/YouTube-real/00004.mp4\n",
       "5  00005.mp4  REAL  ../datasets/Celeb-DF-v2/YouTube-real/00005.mp4\n",
       "6  00006.mp4  REAL  ../datasets/Celeb-DF-v2/YouTube-real/00006.mp4\n",
       "7  00007.mp4  REAL  ../datasets/Celeb-DF-v2/YouTube-real/00007.mp4\n",
       "8  00008.mp4  REAL  ../datasets/Celeb-DF-v2/YouTube-real/00008.mp4\n",
       "9  00009.mp4  REAL  ../datasets/Celeb-DF-v2/YouTube-real/00009.mp4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data for dataframe\n",
    "filenames = []\n",
    "\n",
    "for path in real_data_path:\n",
    "  filenames.append(get_filename(path))\n",
    "labels = [\"REAL\"] * len(real_data_path)\n",
    "\n",
    "for path in fake_data_path:\n",
    "  filenames.append(get_filename(path))\n",
    "labels = labels + [\"FAKE\"] * len(fake_data_path)\n",
    "\n",
    "labels_dict = {\n",
    "  'filename': filenames,\n",
    "  'label': labels,\n",
    "  'fullpath': real_data_path + fake_data_path\n",
    "}\n",
    "\n",
    "# Create dataframe\n",
    "data2 = pd.DataFrame(labels_dict)\n",
    "data2 = data2.sort_values(by='filename', ignore_index=True)\n",
    "data2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d102e06f",
   "metadata": {},
   "source": [
    "#### Simple EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b521030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6529, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1a26e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique inputs: 6529\n"
     ]
    }
   ],
   "source": [
    "# Validate unique values\n",
    "print(\"Unique inputs:\", len(data2['filename'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e2735a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FAKE    5639\n",
       "REAL     890\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb10a710",
   "metadata": {},
   "source": [
    "### FaceForensics++ DeepFakeDetection\n",
    "\n",
    "This dataset is provided by Google and Jigsaw for deepfakes detectionr esearch. Public generation methods were used to create over 3000 manipulated videos from 28 actors in various scenes. \n",
    "\n",
    "The dataset contains approximately 3068 \"FAKE\" videos and 363 \"REAL\" videos.\n",
    "\n",
    "Downloaded using the script:\n",
    "```\n",
    "python faceforensics_download_v4.py . -d DeepFakeDetection -c c23 -t videos      \n",
    "```\n",
    "To download the original unmanipulated dataset:\n",
    "```\n",
    "python faceforensics_download_v4.py . -d DeepFakeDetection_original -c c23 -t videos \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98fdb7b",
   "metadata": {},
   "source": [
    "#### Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6304776",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = \"manipulated_sequences/DeepFakeDetection/c23/videos\"\n",
    "df_file_path = iterate_files(os.path.join(DATA_FACEFORENSICS, df_path))\n",
    "rl_path = \"original_sequences/actors/c23/videos\"\n",
    "rl_file_path = iterate_files(os.path.join(DATA_FACEFORENSICS, rl_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93741a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>fullpath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01_02__exit_phone_room__YVGY8LOK.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>../datasets/DeepfakeDetectionDataset/manipulat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01_02__hugging_happy__YVGY8LOK.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>../datasets/DeepfakeDetectionDataset/manipulat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01_02__meeting_serious__YVGY8LOK.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>../datasets/DeepfakeDetectionDataset/manipulat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01_02__outside_talking_still_laughing__YVGY8LO...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>../datasets/DeepfakeDetectionDataset/manipulat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01_02__secret_conversation__YVGY8LOK.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>../datasets/DeepfakeDetectionDataset/manipulat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01_02__talking_against_wall__YVGY8LOK.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>../datasets/DeepfakeDetectionDataset/manipulat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01_02__talking_angry_couch__YVGY8LOK.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>../datasets/DeepfakeDetectionDataset/manipulat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>01_02__walk_down_hall_angry__YVGY8LOK.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>../datasets/DeepfakeDetectionDataset/manipulat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01_02__walking_and_outside_surprised__YVGY8LOK...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>../datasets/DeepfakeDetectionDataset/manipulat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>01_02__walking_down_indoor_hall_disgust__YVGY8...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>../datasets/DeepfakeDetectionDataset/manipulat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename label  \\\n",
       "0               01_02__exit_phone_room__YVGY8LOK.mp4  FAKE   \n",
       "1                 01_02__hugging_happy__YVGY8LOK.mp4  FAKE   \n",
       "2               01_02__meeting_serious__YVGY8LOK.mp4  FAKE   \n",
       "3  01_02__outside_talking_still_laughing__YVGY8LO...  FAKE   \n",
       "4           01_02__secret_conversation__YVGY8LOK.mp4  FAKE   \n",
       "5          01_02__talking_against_wall__YVGY8LOK.mp4  FAKE   \n",
       "6           01_02__talking_angry_couch__YVGY8LOK.mp4  FAKE   \n",
       "7          01_02__walk_down_hall_angry__YVGY8LOK.mp4  FAKE   \n",
       "8  01_02__walking_and_outside_surprised__YVGY8LOK...  FAKE   \n",
       "9  01_02__walking_down_indoor_hall_disgust__YVGY8...  FAKE   \n",
       "\n",
       "                                            fullpath  \n",
       "0  ../datasets/DeepfakeDetectionDataset/manipulat...  \n",
       "1  ../datasets/DeepfakeDetectionDataset/manipulat...  \n",
       "2  ../datasets/DeepfakeDetectionDataset/manipulat...  \n",
       "3  ../datasets/DeepfakeDetectionDataset/manipulat...  \n",
       "4  ../datasets/DeepfakeDetectionDataset/manipulat...  \n",
       "5  ../datasets/DeepfakeDetectionDataset/manipulat...  \n",
       "6  ../datasets/DeepfakeDetectionDataset/manipulat...  \n",
       "7  ../datasets/DeepfakeDetectionDataset/manipulat...  \n",
       "8  ../datasets/DeepfakeDetectionDataset/manipulat...  \n",
       "9  ../datasets/DeepfakeDetectionDataset/manipulat...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = []\n",
    "for path in df_file_path:\n",
    "  filenames.append(get_filename(path))\n",
    "labels = [\"FAKE\"] * len(df_file_path)\n",
    "\n",
    "for path in rl_file_path:\n",
    "  filenames.append(get_filename(path))\n",
    "labels += [\"REAL\"] * len(rl_file_path)\n",
    "\n",
    "labels_dict = {\n",
    "  'filename': filenames,\n",
    "  'label': labels,\n",
    "  'fullpath': df_file_path + rl_file_path\n",
    "}\n",
    "\n",
    "data3 = pd.DataFrame(labels_dict)\n",
    "data3 = data3.sort_values(by='filename', ignore_index=True)\n",
    "data3.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec9d08a",
   "metadata": {},
   "source": [
    "#### Simple EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9c47526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3431, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1c127b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique inputs: 3431\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique inputs:\", len(data3['filename'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa012fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FAKE    3068\n",
       "REAL     363\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c75b9ea",
   "metadata": {},
   "source": [
    "## Merge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "427867c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column indicating their path\n",
    "data1['dataset'] = KAGGLE_DFDC\n",
    "data2['dataset'] = CELEB_DF\n",
    "data3['dataset'] = FF_DFDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea9ead24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>fullpath</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aagfhgtpmv.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>../datasets/Kaggle-dfdc/train_sample_videos/aa...</td>\n",
       "      <td>Kaggle-dfdc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aapnvogymq.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>../datasets/Kaggle-dfdc/train_sample_videos/aa...</td>\n",
       "      <td>Kaggle-dfdc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaqaifqrwn.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>../datasets/Kaggle-dfdc/dfdc_train_part_0/aaqa...</td>\n",
       "      <td>Kaggle-dfdc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aassnaulhq.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>../datasets/Kaggle-dfdc/dfdc_train_part_1/aass...</td>\n",
       "      <td>Kaggle-dfdc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aayrffkzxn.mp4</td>\n",
       "      <td>REAL</td>\n",
       "      <td>../datasets/Kaggle-dfdc/dfdc_train_part_0/aayr...</td>\n",
       "      <td>Kaggle-dfdc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename label                                           fullpath  \\\n",
       "0  aagfhgtpmv.mp4  FAKE  ../datasets/Kaggle-dfdc/train_sample_videos/aa...   \n",
       "1  aapnvogymq.mp4  FAKE  ../datasets/Kaggle-dfdc/train_sample_videos/aa...   \n",
       "2  aaqaifqrwn.mp4  FAKE  ../datasets/Kaggle-dfdc/dfdc_train_part_0/aaqa...   \n",
       "3  aassnaulhq.mp4  FAKE  ../datasets/Kaggle-dfdc/dfdc_train_part_1/aass...   \n",
       "4  aayrffkzxn.mp4  REAL  ../datasets/Kaggle-dfdc/dfdc_train_part_0/aayr...   \n",
       "\n",
       "       dataset  \n",
       "0  Kaggle-dfdc  \n",
       "1  Kaggle-dfdc  \n",
       "2  Kaggle-dfdc  \n",
       "3  Kaggle-dfdc  \n",
       "4  Kaggle-dfdc  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge dataframes\n",
    "frames = [data1, data2, data3]\n",
    "full_dataset = pd.concat(frames)\n",
    "full_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fe8c96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13393, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3272ce3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique inputs: 13393\n"
     ]
    }
   ],
   "source": [
    "# Validate all unique files\n",
    "print(\"Unique inputs:\", len(full_dataset['filename'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa73f8d4",
   "metadata": {},
   "source": [
    "**Number of video files for each dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e9e5c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Celeb-DF-v2                 6529\n",
       "Kaggle-dfdc                 3433\n",
       "DeepfakeDetectionDataset    3431\n",
       "Name: dataset, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset['dataset'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f946259f",
   "metadata": {},
   "source": [
    "**REAL/FAKE video distribution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c9c3b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FAKE    11869\n",
       "REAL     1524\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d6339c",
   "metadata": {},
   "source": [
    "### Save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b65e09e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"../dataset-full.csv\"\n",
    "\n",
    "full_dataset.to_csv(save_path, index=False)\n",
    "# full_dataset = pd.read_csv(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d003ecb",
   "metadata": {},
   "source": [
    "## Spliting the Dataset\n",
    "\n",
    "From the full dataset above, we can see that the datset is incredibly unbalanced with over 7 times more deepfake videos than real videos. This could potentially lead to overfitting during training.\n",
    "\n",
    "To prevent overfitting, and to reduce compute, we will be sampling the \"FAKE\" videos based on the number of \"REAL\" videos. The final dataset will therefore contain 1524 samples of both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad323ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>fullpath</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id0_0000.mp4</td>\n",
       "      <td>REAL</td>\n",
       "      <td>../datasets/Celeb-DF-v2/Celeb-real/id0_0000.mp4</td>\n",
       "      <td>Celeb-DF-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id0_0001.mp4</td>\n",
       "      <td>REAL</td>\n",
       "      <td>../datasets/Celeb-DF-v2/Celeb-real/id0_0001.mp4</td>\n",
       "      <td>Celeb-DF-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id0_0002.mp4</td>\n",
       "      <td>REAL</td>\n",
       "      <td>../datasets/Celeb-DF-v2/Celeb-real/id0_0002.mp4</td>\n",
       "      <td>Celeb-DF-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id0_0003.mp4</td>\n",
       "      <td>REAL</td>\n",
       "      <td>../datasets/Celeb-DF-v2/Celeb-real/id0_0003.mp4</td>\n",
       "      <td>Celeb-DF-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id0_0004.mp4</td>\n",
       "      <td>REAL</td>\n",
       "      <td>../datasets/Celeb-DF-v2/Celeb-real/id0_0004.mp4</td>\n",
       "      <td>Celeb-DF-v2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       filename label                                         fullpath  \\\n",
       "0  id0_0000.mp4  REAL  ../datasets/Celeb-DF-v2/Celeb-real/id0_0000.mp4   \n",
       "1  id0_0001.mp4  REAL  ../datasets/Celeb-DF-v2/Celeb-real/id0_0001.mp4   \n",
       "2  id0_0002.mp4  REAL  ../datasets/Celeb-DF-v2/Celeb-real/id0_0002.mp4   \n",
       "3  id0_0003.mp4  REAL  ../datasets/Celeb-DF-v2/Celeb-real/id0_0003.mp4   \n",
       "4  id0_0004.mp4  REAL  ../datasets/Celeb-DF-v2/Celeb-real/id0_0004.mp4   \n",
       "\n",
       "       dataset  \n",
       "0  Celeb-DF-v2  \n",
       "1  Celeb-DF-v2  \n",
       "2  Celeb-DF-v2  \n",
       "3  Celeb-DF-v2  \n",
       "4  Celeb-DF-v2  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "\n",
    "fake_data = full_dataset[full_dataset['label'] == \"FAKE\"]\n",
    "real_data = full_dataset[full_dataset['label'] == \"REAL\"]\n",
    "\n",
    "# Take sample of the data\n",
    "fake_sample = fake_data.sample(n=len(real_data), random_state=seed)\n",
    "\n",
    "# Create final dataset\n",
    "sample_dataset = pd.concat([real_data, fake_sample])\n",
    "sample_dataset = sample_dataset.sort_values(by='fullpath', ignore_index=True)\n",
    "\n",
    "sample_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "588ac405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FAKE    1524\n",
       "REAL    1524\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dataset['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "559ec8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Celeb-DF-v2 \n",
      " REAL    890\n",
      "FAKE    725\n",
      "Name: label, dtype: int64 \n",
      "\n",
      "DeepfakeDetectionDataset \n",
      " FAKE    394\n",
      "REAL    363\n",
      "Name: label, dtype: int64 \n",
      "\n",
      "Kaggle-dfdc \n",
      " FAKE    405\n",
      "REAL    271\n",
      "Name: label, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = list(sample_dataset['dataset'].unique())\n",
    "\n",
    "for d in datasets:\n",
    "  vc = sample_dataset[sample_dataset['dataset'] == d]['label'].value_counts()\n",
    "  print(d, '\\n', vc, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c7e6275",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"../dataset-sample.csv\"\n",
    "\n",
    "sample_dataset.to_csv(save_path, index=False)\n",
    "# sample_dataset = pd.read_csv(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74d16dc",
   "metadata": {},
   "source": [
    "## Extract Frames and Faces\n",
    "\n",
    "To make the dataset portable, the faces are extracted from the frames and saved as an image. To reduce the file size, only the faces are saved, not the frames themselves. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e905163b",
   "metadata": {},
   "source": [
    "### FaceExtractor and FrameExtractor\n",
    "\n",
    "To extract the faces from the frames we will be using the MTCNN face detector. MTCNN and RetinaFace were both evaluated in the [Deepfake Detection - Comparing Face Detectors.ipynb](./Deepfake%20Detection%20-%20Comparing%20Face%20Detectors.ipynb) notebook. RetinaFace was clearly demonstrated to be much faster than MTCNN in classification time. In [[1]](https://arxiv.org/pdf/1905.00641v2.pdf), the accuracy for RetinaFace was slightly higher than MTCNN. Benchmarking also showed that RetinaFace was able to achieve a higher precision on the WIDER Face dataset at 0.914 compared to MTCNN 0.809 [[2]](https://paperswithcode.com/sota/face-detection-on-wider-face-hard). \n",
    "\n",
    "However, RetinaFace also had a few weaknesses and features that were not favourable for generating the training dataset. For images where the face dominated the frame, RetinaFace was unable to identify that as face was present, while MTCNN was. In videos where the camera zooms in and out from the subject's face, this can be a detriment as RetinaFace will be unable to detect that the face is present. In circumstances where there is face yaw, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c64252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46822737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# Enables import of modules under 'model' folder\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from extractors import FaceExtractor, FrameExtractor\n",
    "\n",
    "# Config variables\n",
    "extract_path = \"../extracted_faces/\"\n",
    "face_confidence_thresh = 0.87\n",
    "frames_per_video = 32\n",
    "padding = 0.3\n",
    "rescale_video = False\n",
    "\n",
    "face_extractor = FaceExtractor(model=\"mtcnn\", thresh=face_confidence_thresh)\n",
    "\n",
    "def extract_faces(video_source: str, video_filename: str):\n",
    "  \n",
    "  frame_extractor = FrameExtractor(video_source, verbose=False)\n",
    "  \n",
    "  frames = frame_extractor.get_frames_evenly(n_frames=frames_per_video,\n",
    "                                            rescale=rescale_video)\n",
    "  vidname, _ = os.path.splitext(video_filename) \n",
    "  image_path_base = os.path.join(extract_path, vidname)\n",
    "  Path(image_path_base).mkdir(parents=True, exist_ok=True)\n",
    "  \n",
    "  face_filenames = []\n",
    "  face_fullpath = []\n",
    "  face_confidence = []\n",
    "  \n",
    "  for frame in frames:\n",
    "    # Gets the frame_id and frame\n",
    "    loc, img = frame['loc'], frame['frame']\n",
    "    # Extracts only the best face from the frame \n",
    "    face, conf = face_extractor.crop_best_face(img, padding=padding)\n",
    "    if face is not None:\n",
    "      image_filename = f\"{vidname}_{loc}.png\"\n",
    "      image_path = os.path.join(image_path_base, image_filename)\n",
    "      cv2.imwrite(image_path, face)\n",
    "      face_filenames.append(image_filename)\n",
    "      face_fullpath.append(image_path)\n",
    "      face_confidence.append(conf)\n",
    "  \n",
    "  res = {\n",
    "    \"video_filename\": video_filename,\n",
    "    \"image_filename\": face_filenames,\n",
    "    \"image_fullpath\": face_fullpath,\n",
    "    \"face_confidence\":  face_confidence\n",
    "  }\n",
    "  return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b36f870",
   "metadata": {},
   "source": [
    "### GPU config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6aacc3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turns off plaidml warnings (a plugin that enables tensorflow gpu on a Mac)\n",
    "!export PLAIDML_VERBOSE=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b2d4dae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27107575",
   "metadata": {},
   "source": [
    "### Extracting faces with MultiThreading enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0ee7d24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|████████▍                                                                                                         | 226/3048 [1:47:27<13:59:48, 17.86s/it]2022-05-26 20:37:20.038752: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3048/3048 [23:33:43<00:00, 27.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete in 23 hours(s) 33 minute(s) 82843.47 second(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def time_delta_str(seconds) -> str:\n",
    "  h = int(seconds/(60*60))\n",
    "  m = int( (seconds - (h * 60 * 60)) / 60 )\n",
    "  s = round( seconds - (m * 60), 2 )\n",
    "  delta = \"{} hours(s) {} minute(s) {} second(s)\".format(h, m, s)\n",
    "  return delta\n",
    "\n",
    "def run_extract_faces(limit, workers):\n",
    "  # Proxy function for extract_frames using dataframe ilocs\n",
    "  def extract_faces_proxy(i):\n",
    "    return extract_faces(sample_dataset[\"fullpath\"].iloc[i], sample_dataset[\"filename\"].iloc[i])\n",
    "  \n",
    "  # Creates a list of indices\n",
    "  ilocs = list(np.arange(limit))\n",
    "  \n",
    "  stime = time.time()\n",
    "  with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n",
    "      results = list(tqdm(executor.map(extract_faces_proxy, ilocs), total=limit))\n",
    "  etime = time.time()\n",
    "  print(\"Complete in\", time_delta_str(etime-stime))\n",
    "  return results\n",
    "\n",
    "extracted_files = run_extract_faces(limit=len(sample_dataset), workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea22cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves variable in format\n",
    "import pickle\n",
    "\n",
    "with open(\"pickle/exported_files.pickle\", \"wb\") as f:\n",
    "  pickle.dump(extracted_files, f)\n",
    "  \n",
    "with open(\"pickle/exported_files.pickle\", \"rb\") as f:\n",
    "  extracted_files = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7027c4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3048"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extracted_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6057aa3",
   "metadata": {},
   "source": [
    "### Create final training dataset\n",
    "\n",
    "The goal is to create an image dataset file with the following columns:\n",
    "- `image_filename`: filename of the image\n",
    "- `image_fullpath`: relative path location of the image\n",
    "- `face_confidence`: confidence level detected by MTCNN\n",
    "- `label`\n",
    "- `video_filename`\n",
    "- `video_fullpath`\n",
    "- `video_dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "98673ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'REAL'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid_filename = \"id0_0000.mp4\"\n",
    "sample_dataset[sample_dataset['filename']==vid_filename]['label'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "51083b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 3048/3048 [24:09<00:00,  2.10it/s]\n"
     ]
    }
   ],
   "source": [
    "columns = [\n",
    "  'image_filename',\n",
    "  'image_fullpath',\n",
    "  'face_confidence',\n",
    "  'label',\n",
    "  'video_filename',\n",
    "  'video_fullpath',\n",
    "  'video_dataset'\n",
    "]\n",
    "face_dataset = pd.DataFrame(columns=columns)\n",
    "\n",
    "for images in tqdm(extracted_files):\n",
    "  vid_filename = images['video_filename']\n",
    "  sample_ref = sample_dataset[sample_dataset['filename']==vid_filename]\n",
    "  \n",
    "  vid_deets = {}\n",
    "  vid_deets['video_filename'] = vid_filename\n",
    "  vid_deets['video_fullpath'] = sample_ref['fullpath'].iloc[0]\n",
    "  vid_deets['video_dataset'] = sample_ref['dataset'].iloc[0]\n",
    "  vid_deets['label'] = sample_ref['label'].iloc[0]\n",
    "  \n",
    "  image_deets = {}\n",
    "  for i in range(len(images['image_filename'])):\n",
    "    image_deets['image_filename'] = images['image_filename'][i]\n",
    "    image_deets['image_fullpath'] = images['image_fullpath'][i]\n",
    "    image_deets['face_confidence'] = images['face_confidence'][i]\n",
    "    \n",
    "    row = dict(vid_deets, **image_deets)\n",
    "    face_dataset = face_dataset.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f610a25f",
   "metadata": {},
   "source": [
    "### Face Dataset EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d754744d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95032, 7)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4069008d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REAL    48200\n",
       "FAKE    46832\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_dataset['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "24f7e097",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 3048/3048 [00:00<00:00, 151687.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete in 0 hours(s) 0 minute(s) 0.19 second(s)\n",
      "All files exist:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify the existence of a file\n",
    "def verify_files_exist(workers:int):\n",
    "  \n",
    "  # If file is not true, returns filepath\n",
    "  def file_doesnt_exist(i):\n",
    "    path = face_dataset['image_fullpath'].iloc[i]\n",
    "    if not os.path.isfile(path):\n",
    "      return path\n",
    "    return None\n",
    "  \n",
    "  # Creates a list of indices\n",
    "  ilocs = np.arange(len(sample_dataset))\n",
    "  \n",
    "  stime = time.time()\n",
    "  with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n",
    "      results = list(tqdm(executor.map(file_doesnt_exist, ilocs), total=len(sample_dataset)))\n",
    "  etime = time.time()\n",
    "  \n",
    "  # Removes None from results\n",
    "  results = list(filter(None, results))\n",
    "  \n",
    "  print(\"Complete in\", time_delta_str(etime-stime))\n",
    "  \n",
    "  return len(results) == 0, results\n",
    "\n",
    "\n",
    "files_exist, res = verify_files_exist(workers=8)\n",
    "print(\"All files exist: \", files_exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dd1a643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset\n",
    "save_path = \"../dataset-sample-faces.csv\"\n",
    "\n",
    "face_dataset.to_csv(save_path, index=False)\n",
    "# face_dataset = pd.read_csv(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224edae1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
