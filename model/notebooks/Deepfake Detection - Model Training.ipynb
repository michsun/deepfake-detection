{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cd4616c",
   "metadata": {},
   "source": [
    "# Deepfake Detection - Model Load\n",
    "\n",
    "1. Load the model from extracted faces csv file.\n",
    "2. Setup a sample ResNet with pre-trained 'imagenet' weights.\n",
    "3. Train model\n",
    "4. Write test function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e4b00e",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63a35a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.13'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b9844b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.8.0', '2.8.0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.__version__, keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e342371e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check GPUs available\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Enables use of the GPU on a Mac using plaidml (ignore otherwise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "56ba020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d319df9b",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbea5173",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"../dataset-sample-faces.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "154fdaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_filename</th>\n",
       "      <th>image_fullpath</th>\n",
       "      <th>face_confidence</th>\n",
       "      <th>label</th>\n",
       "      <th>video_filename</th>\n",
       "      <th>video_fullpath</th>\n",
       "      <th>video_dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id0_0000_1.png</td>\n",
       "      <td>../extracted_faces/id0_0000/id0_0000_1.png</td>\n",
       "      <td>0.997610</td>\n",
       "      <td>REAL</td>\n",
       "      <td>id0_0000.mp4</td>\n",
       "      <td>../datasets/Celeb-DF-v2/Celeb-real/id0_0000.mp4</td>\n",
       "      <td>Celeb-DF-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id0_0000_15.png</td>\n",
       "      <td>../extracted_faces/id0_0000/id0_0000_15.png</td>\n",
       "      <td>0.996413</td>\n",
       "      <td>REAL</td>\n",
       "      <td>id0_0000.mp4</td>\n",
       "      <td>../datasets/Celeb-DF-v2/Celeb-real/id0_0000.mp4</td>\n",
       "      <td>Celeb-DF-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id0_0000_29.png</td>\n",
       "      <td>../extracted_faces/id0_0000/id0_0000_29.png</td>\n",
       "      <td>0.999750</td>\n",
       "      <td>REAL</td>\n",
       "      <td>id0_0000.mp4</td>\n",
       "      <td>../datasets/Celeb-DF-v2/Celeb-real/id0_0000.mp4</td>\n",
       "      <td>Celeb-DF-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id0_0000_43.png</td>\n",
       "      <td>../extracted_faces/id0_0000/id0_0000_43.png</td>\n",
       "      <td>0.995511</td>\n",
       "      <td>REAL</td>\n",
       "      <td>id0_0000.mp4</td>\n",
       "      <td>../datasets/Celeb-DF-v2/Celeb-real/id0_0000.mp4</td>\n",
       "      <td>Celeb-DF-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id0_0000_57.png</td>\n",
       "      <td>../extracted_faces/id0_0000/id0_0000_57.png</td>\n",
       "      <td>0.997212</td>\n",
       "      <td>REAL</td>\n",
       "      <td>id0_0000.mp4</td>\n",
       "      <td>../datasets/Celeb-DF-v2/Celeb-real/id0_0000.mp4</td>\n",
       "      <td>Celeb-DF-v2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_filename                               image_fullpath  \\\n",
       "0   id0_0000_1.png   ../extracted_faces/id0_0000/id0_0000_1.png   \n",
       "1  id0_0000_15.png  ../extracted_faces/id0_0000/id0_0000_15.png   \n",
       "2  id0_0000_29.png  ../extracted_faces/id0_0000/id0_0000_29.png   \n",
       "3  id0_0000_43.png  ../extracted_faces/id0_0000/id0_0000_43.png   \n",
       "4  id0_0000_57.png  ../extracted_faces/id0_0000/id0_0000_57.png   \n",
       "\n",
       "   face_confidence label video_filename  \\\n",
       "0         0.997610  REAL   id0_0000.mp4   \n",
       "1         0.996413  REAL   id0_0000.mp4   \n",
       "2         0.999750  REAL   id0_0000.mp4   \n",
       "3         0.995511  REAL   id0_0000.mp4   \n",
       "4         0.997212  REAL   id0_0000.mp4   \n",
       "\n",
       "                                    video_fullpath video_dataset  \n",
       "0  ../datasets/Celeb-DF-v2/Celeb-real/id0_0000.mp4   Celeb-DF-v2  \n",
       "1  ../datasets/Celeb-DF-v2/Celeb-real/id0_0000.mp4   Celeb-DF-v2  \n",
       "2  ../datasets/Celeb-DF-v2/Celeb-real/id0_0000.mp4   Celeb-DF-v2  \n",
       "3  ../datasets/Celeb-DF-v2/Celeb-real/id0_0000.mp4   Celeb-DF-v2  \n",
       "4  ../datasets/Celeb-DF-v2/Celeb-real/id0_0000.mp4   Celeb-DF-v2  "
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(DATASET_PATH)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "540355f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image_filename',\n",
       " 'image_fullpath',\n",
       " 'face_confidence',\n",
       " 'label',\n",
       " 'video_filename',\n",
       " 'video_fullpath',\n",
       " 'video_dataset']"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "ac480672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REAL    48200\n",
       "FAKE    46832\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4daec9",
   "metadata": {},
   "source": [
    "Although, there is a slight imbalance in the dataset as seen above, we sampled the number of \"FAKE\" videos equal to the number of \"REAL\" videos in the notebook [Deepfake Detection - Dataset Preparation.ipynb](./Deepfake%20Detection%20-%20Dataset%20Preparation.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15f3d03",
   "metadata": {},
   "source": [
    "## Data Splitting\n",
    "\n",
    "To ensure that images from a video in the train dataset is not in the validation/test dataset, a custom split function was made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "27075ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(data, test_size, column, shuffle=False, random_state=1):\n",
    "  \"\"\"Splits the dataframe based on unique values in a given \n",
    "  column.\"\"\"\n",
    "  # Gets a list of unique videos \n",
    "  videos = list(data[column].unique())\n",
    "  n = len(videos)\n",
    "  k = int(0.2 * n)\n",
    "\n",
    "  if shuffle:\n",
    "    data = data.sample(frac=1)\n",
    "\n",
    "  # Sets the random state\n",
    "  random.seed(random_state)\n",
    "  split_videos = random.sample(videos, k)\n",
    "\n",
    "  df1 = data[data[column].isin(split_videos)]\n",
    "  df2 = data[~data[column].isin(split_videos)]\n",
    "  \n",
    "  assert(len(df1[df1.isin(df2)].dropna()) == 0)\n",
    "  \n",
    "  df1.sort_index(inplace=True)\n",
    "  df2.sort_index(inplace=True)\n",
    "  \n",
    "  return df2, df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "3210e0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hp/zn9_yg9d1tz9_w596brfcm580000gn/T/ipykernel_74701/1251354954.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.sort_index(inplace=True)\n",
      "/var/folders/hp/zn9_yg9d1tz9_w596brfcm580000gn/T/ipykernel_74701/1251354954.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2.sort_index(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SPLIT = 0.2\n",
    "VAL_SPLIT = 0.25\n",
    "\n",
    "train_df, test_df = split_dataframe(data=data, \n",
    "                                    test_size=TRAIN_SPLIT,\n",
    "                                    column=\"video_filename\",\n",
    "                                    shuffle=True,\n",
    "                                    random_state=42)\n",
    "\n",
    "train_df, val_df = split_dataframe(data=data, \n",
    "                                  test_size=VAL_SPLIT,\n",
    "                                  column=\"video_filename\",\n",
    "                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "28c415ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REAL    38836\n",
       "FAKE    37156\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "1e74a189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FAKE    9676\n",
       "REAL    9364\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "5130182a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FAKE    9676\n",
       "REAL    9364\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5caa62",
   "metadata": {},
   "source": [
    "## Data Augmentation \n",
    "\n",
    "**Gaussian Noise:**\n",
    "\n",
    "**Random Erasing:** https://arxiv.org/abs/1708.04896\n",
    "    - Source code: https://github.com/zhunzhong07/Random-Erasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "3e687c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def gaussian_noise(image, probability):\n",
    "  if random.uniform(0,1) > probability:\n",
    "    return image\n",
    "  row,col,ch= image.shape\n",
    "  mean = 0\n",
    "  var = 0.01 # slightly reduced\n",
    "  sigma = var ** 0.5\n",
    "  gauss = np.random.normal(mean,sigma,(row,col))\n",
    "  noisy = image\n",
    "  for i in range(ch):\n",
    "    noisy[:,:,i] = image[:,:,i] + gauss\n",
    "  return noisy\n",
    "\n",
    "\n",
    "def random_erasing(img, probability):\n",
    "  \"\"\"\n",
    "  Performs Random Erasing in Random Erasing Data Augmentation by Zhong et al.\n",
    "\n",
    "  probability: The probability that the operation will be performed.\n",
    "  sl: min erasing area\n",
    "  sh: max erasing area\n",
    "  r1: min aspect ratio\n",
    "  mean: erasing value\n",
    "\n",
    "  Note: Code modified for img.shape parameters instead of img.size()\n",
    "  \"\"\"\n",
    "  # Source: https://github.com/zhunzhong07/Random-Erasing\n",
    "  if random.uniform(0,1) > probability:\n",
    "    return img\n",
    "\n",
    "  # Default params\n",
    "  mean = [0.4914, 0.4822, 0.4465]\n",
    "  sl = 0.02\n",
    "  sh = 0.4\n",
    "  r1 = 0.3\n",
    "\n",
    "  for attempt in range(100):\n",
    "    area = img.shape[0] * img.shape[1]\n",
    "\n",
    "    target_area = random.uniform(sl, sh) * area\n",
    "    aspect_ratio = random.uniform(r1, 1/r1)\n",
    "\n",
    "    h = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "    w = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "\n",
    "    if w < img.shape[0] and h < img.shape[1]:\n",
    "        x1 = random.randint(0, img.shape[1] - h)\n",
    "        y1 = random.randint(0, img.shape[0] - w)\n",
    "        if img.shape[2] == 3:\n",
    "            img[x1:x1+h, y1:y1+w, 0] = mean[0]\n",
    "            img[x1:x1+h, y1:y1+w, 1] = mean[1]\n",
    "            img[x1:x1+h, y1:y1+w, 2] = mean[2]\n",
    "        else:\n",
    "            img[0, x1:x1+h, y1:y1+w] = mean[0]\n",
    "\n",
    "        return img\n",
    "  return img\n",
    "\n",
    "class CustomDataGenerator(ImageDataGenerator):\n",
    "  '''\n",
    "  Custom image data generator.\n",
    "  Allows image compression and random erasing.\n",
    "  '''\n",
    "  def __init__(self, \n",
    "               gaussian_noise : float = 0., \n",
    "               random_erasing : float = 0.,\n",
    "               **kwargs):\n",
    "    super().__init__(preprocessing_function=self.custom_augmentations,\n",
    "                    **kwargs)\n",
    "    self.gaussian_noise = gaussian_noise\n",
    "    self.random_erasing = random_erasing\n",
    "  \n",
    "  def custom_augmentations(self, image):\n",
    "    image = gaussian_noise(image, self.gaussian_noise)\n",
    "    image = random_erasing(image, self.random_erasing)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "8f6e22d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = CustomDataGenerator(rescale=1./255,\n",
    "                                  zoom_range=0.2,\n",
    "                                  rotation_range=0.1,\n",
    "                                  horizontal_flip=True,\n",
    "                                  # Custom augmentation probabilities\n",
    "                                  gaussian_noise=0.1,\n",
    "                                  random_erasing=0.3)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "f9cdb8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75992 validated image filenames belonging to 2 classes.\n",
      "Found 19040 validated image filenames belonging to 2 classes.\n",
      "Found 19040 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "  dataframe = train_df,\n",
    "  directory = \".\",\n",
    "  x_col = \"image_fullpath\",\n",
    "  y_col = \"label\",\n",
    "  batch_size = 34,\n",
    "  seed = 42,\n",
    "  class_mode = \"binary\",\n",
    "  target_size=(128, 128)\n",
    ")\n",
    "\n",
    "valid_generator = train_datagen.flow_from_dataframe(\n",
    "  dataframe = val_df,\n",
    "  directory = \".\",\n",
    "  x_col = \"image_fullpath\",\n",
    "  y_col = \"label\",\n",
    "  batch_size = 34,\n",
    "  seed = 42,\n",
    "  class_mode = \"binary\",\n",
    "  target_size=(128, 128)\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "  dataframe = test_df, \n",
    "  directory = \".\",\n",
    "  x_col = \"image_fullpath\",\n",
    "  y_col = \"label\",\n",
    "  batch_size=34,\n",
    "  seed = 42,\n",
    "  shuffle=False,\n",
    "  class_mode=\"binary\",\n",
    "  target_size=(128, 128)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6610f337",
   "metadata": {},
   "source": [
    "## Resnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "b21ab041",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet:\n",
    "    def __init__(self, input_size, n_freeze=143):\n",
    "        self.input_size = input_size\n",
    "        self.n_freeze = n_freeze\n",
    "        self.model = self._initialise_model()\n",
    "        self.history = None\n",
    "    \n",
    "    def _initialise_model(self):\n",
    "        from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "        input_t = keras.Input(shape=self.input_size)\n",
    "        base_model = ResNet50(weights='imagenet',\n",
    "                             include_top=False,\n",
    "                             input_tensor=input_t\n",
    "        )\n",
    "        if self.n_freeze:\n",
    "            for layer in base_model.layers[:self.n_freeze]:\n",
    "                layer.trainable = False\n",
    "        else:\n",
    "            for layer in base_model.layers:\n",
    "                layer.trainable = False\n",
    "        \n",
    "        model = keras.models.Sequential()\n",
    "        model.add(base_model)\n",
    "        model.add(keras.layers.Flatten())\n",
    "#         model.add(keras.layers.BatchNormalization())\n",
    "#         model.add(keras.layers.Dense(128, activation='relu', kernel_regularizer='l2'))\n",
    "#         model.add(keras.layers.Dropout(0.5))\n",
    "#         model.add(keras.layers.BatchNormalization())\n",
    "#         model.add(keras.layers.Dense(64, activation='relu', kernel_regularizer='l2'))\n",
    "        model.add(keras.layers.Dropout(0.25))\n",
    "#         model.add(keras.layers.BatchNormalization())\n",
    "        model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "        return model\n",
    "    \n",
    "    def train_model(self, train_generator, valid_generator,\n",
    "                   epochs, learning_rate=0.0001,\n",
    "                   save_model:str=None,\n",
    "                   verbose=1):\n",
    "        train_steps = len(train_generator)\n",
    "        val_steps = len(valid_generator)\n",
    "      \n",
    "        self.model.compile(\n",
    "            loss='binary_crossentropy',\n",
    "            optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        self.history = self.model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=train_steps,\n",
    "            epochs=epochs,\n",
    "            validation_data=valid_generator,\n",
    "            validation_steps=val_steps,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        \n",
    "        if save_model is not None:\n",
    "          self.save_model(save_model)\n",
    "        return self.history.history\n",
    "\n",
    "    def save_model(self,filepath):\n",
    "        self.model.save(filepath)\n",
    "\n",
    "    def get_history(self):\n",
    "        return self.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "c2f7f9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 4, 4, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 32769     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,620,481\n",
      "Trainable params: 15,008,769\n",
      "Non-trainable params: 8,611,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(input_size=(128,128,3))\n",
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "7d569c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 03:49:49.934452: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 225/2236 [==>...........................] - ETA: 23:22 - loss: 1.2401 - accuracy: 0.5086"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [495]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mvalid_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msave_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../weights/resnet50.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [493]\u001b[0m, in \u001b[0;36mResNet.train_model\u001b[0;34m(self, train_generator, valid_generator, epochs, learning_rate, save_model, verbose)\u001b[0m\n\u001b[1;32m     40\u001b[0m val_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(valid_generator)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     43\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     44\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mRMSprop(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate),\n\u001b[1;32m     45\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     46\u001b[0m )\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(save_model)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train_model(train_generator=train_generator,\n",
    "                 valid_generator=valid_generator,\n",
    "                 epochs=50,\n",
    "                 save_model=\"../weights/resnet50.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d1e20e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6678ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd82b99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
