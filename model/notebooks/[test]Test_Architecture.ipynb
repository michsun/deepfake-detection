{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de2fb012",
   "metadata": {},
   "source": [
    "# Deepfake Detection Test\n",
    "\n",
    "**Key Resources:**\n",
    "\n",
    "- [Kaggle 1st place solution](https://www.kaggle.com/competitions/deepfake-detection-challenge/discussion/145721#818975)\n",
    "- [Kaggle 3rd place solution](https://www.kaggle.com/competitions/deepfake-detection-challenge/discussion/158158#884330)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0a059dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3.8.13', '2.8.0', '2.8.0')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from platform import python_version\n",
    "\n",
    "python_version(), tf.__version__, keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e0a7b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "\n",
    "from IPython.display import Video\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "DATA_PATH = \"../datasets/Kaggle-Deepfake-Detection-Challenge/\"\n",
    "\n",
    "TRAIN_PATH = DATA_PATH + \"train_sample_videos\"\n",
    "TEST_PATH = DATA_PATH + \"test_videos\"\n",
    "LABEL_PATH = DATA_PATH + \"train_sample_videos/metadata.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e963af7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/michellesun/Dropbox/dev/IN_PROGRESS/deepfake-detection/model/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8063fee",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b956e3fa",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bc46a44",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('aagfhgtpmv.mp4', {'label': 'FAKE', 'split': 'train', 'original': 'vudstovrck.mp4'})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aagfhgtpmv.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>vudstovrck.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aapnvogymq.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>jdubbvfswz.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abarnvbtwb.mp4</td>\n",
       "      <td>REAL</td>\n",
       "      <td>train</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abofeumbvv.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>atvmxvwyns.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abqwwspghj.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>qzimuostzz.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>acifjvzvpm.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>kbvibjhfzo.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>acqfdwsrhi.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>ccfoszqabv.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>acxnxvbsxk.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>fjlyaizcwc.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>acxwigylke.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>ffcwhpnpuw.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aczrgyricp.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>slwkmefgde.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename label  split        original\n",
       "0  aagfhgtpmv.mp4  FAKE  train  vudstovrck.mp4\n",
       "1  aapnvogymq.mp4  FAKE  train  jdubbvfswz.mp4\n",
       "2  abarnvbtwb.mp4  REAL  train            None\n",
       "3  abofeumbvv.mp4  FAKE  train  atvmxvwyns.mp4\n",
       "4  abqwwspghj.mp4  FAKE  train  qzimuostzz.mp4\n",
       "5  acifjvzvpm.mp4  FAKE  train  kbvibjhfzo.mp4\n",
       "6  acqfdwsrhi.mp4  FAKE  train  ccfoszqabv.mp4\n",
       "7  acxnxvbsxk.mp4  FAKE  train  fjlyaizcwc.mp4\n",
       "8  acxwigylke.mp4  FAKE  train  ffcwhpnpuw.mp4\n",
       "9  aczrgyricp.mp4  FAKE  train  slwkmefgde.mp4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels\n",
    "with open(LABEL_PATH, 'r', encoding='utf-8') as f:\n",
    "  labels_dict = json.load(f)\n",
    "\n",
    "# Preview first line of labels_dict\n",
    "print(next(iter(labels_dict.items())))\n",
    "\n",
    "# Restructure dictionary for pandas dataframe input {'col':[1, 2], 'col2':[3, 4]}\n",
    "filenames = list(labels_dict.keys())\n",
    "labels = [ labels_dict[name]['label'] for name in filenames ]\n",
    "splits = [ labels_dict[name]['split'] for name in filenames ]\n",
    "originals = [ labels_dict[name]['original'] for name in filenames ]\n",
    "labels_dict = {\n",
    "  'filename': filenames,\n",
    "  'label': labels,\n",
    "  'split': splits,\n",
    "  'original': originals\n",
    "}\n",
    "\n",
    "# \n",
    "labels = pd.DataFrame(labels_dict)\n",
    "labels.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e228e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c88b9615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique inputs: 400\n"
     ]
    }
   ],
   "source": [
    "# Validate unique values\n",
    "print(\"Unique inputs:\", len(labels['filename'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08712964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "atvmxvwyns.mp4    6\n",
       "meawmsgiti.mp4    6\n",
       "kgbkktcjxf.mp4    5\n",
       "qeumxirsme.mp4    5\n",
       "gjypopglvi.mp4    4\n",
       "                 ..\n",
       "znjupdqnwo.mp4    1\n",
       "hyhjfdxqxy.mp4    1\n",
       "kbvibjhfzo.mp4    1\n",
       "lmlyvmfbbe.mp4    1\n",
       "gnyspcpbhd.mp4    1\n",
       "Name: original, Length: 209, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['original'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1df021c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    400\n",
       "Name: split, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['split'].value_counts() # all train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94e96d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FAKE    323\n",
       "REAL     77\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f3b624",
   "metadata": {},
   "source": [
    "**Observation:** Data imbalance with significantly more FAKE videos than real. Potential bias towards FAKE videos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030066d9",
   "metadata": {},
   "source": [
    "### Load Deepfake Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1fea3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def isdir(fullpath: str) -> bool:\n",
    "    \"\"\"Returns true if is a file, and false if otherwise (a directory).\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(fullpath):\n",
    "            if os.path.isdir(fullpath):\n",
    "                return True\n",
    "            return False\n",
    "    except FileNotFoundError:\n",
    "        print(f'{fullpath} does not exist.')\n",
    "\n",
    "def iterate_files(directory: str) -> List:\n",
    "    \"\"\"Iterates over the files in the given directory and returns a list of \n",
    "    found files.\"\"\"\n",
    "    files = []\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        fullpath = os.path.join(directory, filename)\n",
    "        if (isdir(fullpath)):\n",
    "            files += iterate_files(fullpath)\n",
    "        else:\n",
    "            files.append(fullpath)\n",
    "    return files\n",
    "  \n",
    "def get_filename(source: str):\n",
    "    \"\"\"Returns the filename given a full path.\"\"\"\n",
    "    return os.path.basename(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02743e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset currently \n",
    "dataset = iterate_files(TRAIN_PATH)\n",
    "\n",
    "# Removes label (metadata.json) from dataset\n",
    "if LABEL_PATH in dataset:\n",
    "  dataset.remove(LABEL_PATH)\n",
    "\n",
    "# Sorts alphabetically\n",
    "dataset = sorted(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2798756f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hp/zn9_yg9d1tz9_w596brfcm580000gn/T/ipykernel_60450/863592291.py:1: DeprecationWarning: This function is deprecated. Please call randint(1, 400 + 1) instead\n",
      "  random_video = dataset[np.random.random_integers(1,len(dataset))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted 10 frames from benmsfzfaz.mp4.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"../datasets/Kaggle-Deepfake-Detection-Challenge/train_sample_videos/benmsfzfaz.mp4\" controls  width=\"500\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_video = dataset[np.random.random_integers(1,len(dataset))]\n",
    "EXPORT_PATH = \"extracted_frames\"\n",
    "\n",
    "def get_frames_evenly(video_source: str, n_frames: int) -> List[str]:\n",
    "  \"\"\"\n",
    "  Exports n_frames number of frames from the video_source distributed\n",
    "  evenly across the video.\n",
    "  \n",
    "  :return: list of paths for the exported frames\n",
    "  \"\"\"\n",
    "  vidcap = cv2.VideoCapture(video_source)\n",
    "  total_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT)) \n",
    "  if n_frames > 0 and n_frames <= total_frames:\n",
    "    step = int(total_frames/n_frames)\n",
    "    frames = np.arange(1,total_frames+1,step)\n",
    "  else:\n",
    "    frames = np.arange(1,total_frames,1)\n",
    "  \n",
    "  video_name = os.path.splitext(get_filename(video_source))[0] + \"/\"\n",
    "  export_loc = os.path.join(EXPORT_PATH, video_name)\n",
    "  Path(export_loc).mkdir(parents=True, exist_ok=True)\n",
    "  exported_files = []\n",
    "  for i in frames:\n",
    "    vidcap.set(1,i)\n",
    "    success, image = vidcap.read()\n",
    "    exported_path = os.path.join(export_loc, f\"frame{i}.jpg\")\n",
    "    cv2.imwrite(exported_path, image)\n",
    "    exported_files.append(exported_path)\n",
    "  \n",
    "  print(f\"Successfully extracted {n_frames} frames from {get_filename(video_source)}.\")\n",
    "  return exported_files\n",
    "\n",
    "random_video = dataset[100]\n",
    "extracted_frames = get_frames_evenly(random_video, n_frames=10)\n",
    "\n",
    "Video(random_video, width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03256cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['extracted_frames/benmsfzfaz/frame1.jpg',\n",
       " 'extracted_frames/benmsfzfaz/frame31.jpg',\n",
       " 'extracted_frames/benmsfzfaz/frame61.jpg',\n",
       " 'extracted_frames/benmsfzfaz/frame91.jpg',\n",
       " 'extracted_frames/benmsfzfaz/frame121.jpg',\n",
       " 'extracted_frames/benmsfzfaz/frame151.jpg',\n",
       " 'extracted_frames/benmsfzfaz/frame181.jpg',\n",
       " 'extracted_frames/benmsfzfaz/frame211.jpg',\n",
       " 'extracted_frames/benmsfzfaz/frame241.jpg',\n",
       " 'extracted_frames/benmsfzfaz/frame271.jpg']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb00314d",
   "metadata": {},
   "source": [
    "## Facial Detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6c4316",
   "metadata": {},
   "source": [
    "Using deepface facial detector: https://github.com/serengil/deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "405f595d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'deepface'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeepFace\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_bounding_box\u001b[39m(image_path):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124;03m\"\"\"Returns the bounding box using the deepface analyze function.\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deepface'"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "\n",
    "def get_bounding_box(image_path):\n",
    "    \"\"\"Returns the bounding box using the deepface analyze function.\"\"\"\n",
    "    actions=['age','gender','race','emotion']\n",
    "    res = DeepFace.analyze(img_path=image_path, actions=['emotion'])\n",
    "    res = res['region']\n",
    "    x, y, w, h = res['x'], res['y'], res['w'], res['h']\n",
    "    return x, y, w, h\n",
    "\n",
    "type(get_bounding_box(extracted_frames[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9511551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn import MTCNN\n",
    "\n",
    "detector = MTCNN()\n",
    "\n",
    "img_path = extracted_frames[0]\n",
    "img = cv2.imread(img_path)\n",
    "detector.detect_faces(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b44aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "file = extracted_frames[0]\n",
    "\n",
    "img = cv2.imread(file)\n",
    "mask = np.array(Image.open(file))\n",
    "\n",
    "x, y, w, h = get_bounding_box(file)\n",
    "out = cv2.rectangle(img.copy(), (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "# Show image with bounding box\n",
    "cv2.imshow('img_' + 'test', out)\n",
    "\n",
    "# Show mask\n",
    "cv2.imshow('mask', mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1) # must include to prevent not responding on Mac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca629fd",
   "metadata": {},
   "source": [
    "# Drawing Face on video test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d73640cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m thresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m----> 2\u001b[0m video_path \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(get_filename(video_path))\n\u001b[1;32m      5\u001b[0m vc \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(video_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "thresh = 0.5\n",
    "video_path = dataset[0]\n",
    "print(get_filename(video_path))\n",
    "\n",
    "vc = cv2.VideoCapture(video_path)\n",
    "\n",
    "scale_percent = 50\n",
    "width = int(vc.get(cv2.CAP_PROP_FRAME_WIDTH) * scale_percent/100)\n",
    "height = int(vc.get(cv2.CAP_PROP_FRAME_HEIGHT) * scale_percent/100)\n",
    "dim = (width, height)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        success, frame = vc.read()\n",
    "        if success:\n",
    "            frame = cv2.resize(frame, dim, interpolation=cv2.INTER_AREA)\n",
    "            result = detector.detect_faces(frame)[0]\n",
    "            x, y, w, h = result['box'][0], result['box'][1], result['box'][2], result['box'][3]\n",
    "            out = cv2.rectangle(frame.copy(), (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            cv2.imshow('frame', out)\n",
    "            if cv2.waitKey(1) and 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    vc.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66a8f7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "facf98b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 90]\n",
    "result, encimg = cv2.imencode(img_path, img, encode_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d9ca7b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path)\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a456e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
